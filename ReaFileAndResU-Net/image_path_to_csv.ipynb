{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据说明：\n",
    "   此处的Image是 [百度车道线](https://aistudio.baidu.com/aistudio/competition/detail/5)初级的数据集，但是下载下来发现数据集里面的图片位置和想要遍历的目标文件有一定的差别，所以对数据集文件进行了整理。把训练样本和标签分别放入Image和Label文件夹当中，这样方便文件的获取和训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as pjoin\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "img_dir = \"F:\\\\BaiDuData\\\\data\\\\Imgae\"\n",
    "lab_dir = \"F:\\\\BaiDuData\\\\data\\\\Label\"\n",
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows系统读取文件\n",
    "如下部分在win10下利用**os.path.join**进行路径连接时，生成的路径是以 **“\\”** 进行连接的，但是这样会把 **路径连接符当成转移符**，导致读取的路径错误，所以此处没有运用 **os.path.join()** 函数进行路径连接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def win_img_path(path):\n",
    "    list_img = []\n",
    "    list_lab = []\n",
    "\n",
    "    for path_1 in os.listdir(path[0]):\n",
    "        img_sub_dir1 = path[0] + \"\\\\\" + path_1 \n",
    "        lab_sub_dir1 = path[1] + \"\\\\\" + \"Label_\" + str.lower(path_1) + \"\\\\\" + 'Label'\n",
    "        for path_2 in os.listdir(img_sub_dir1):\n",
    "            img_sub_dir2 = img_sub_dir1+\"\\\\\" + path_2\n",
    "            lab_sub_dir2 = lab_sub_dir1+\"\\\\\" + path_2\n",
    "            for path_3 in os.listdir(img_sub_dir2):\n",
    "                img_sub_dir3 = img_sub_dir2+\"\\\\\" + path_3\n",
    "                lab_sub_dir3 = lab_sub_dir2+\"\\\\\" + path_3\n",
    "                for path_4 in os.listdir(img_sub_dir3):\n",
    "                    path_4_lab = path_4.replace(\".jpg\", \"_bin.png\")\n",
    "                    img_sub_dir4 = img_sub_dir3+\"\\\\\" + path_4\n",
    "                    lab_sub_dir4 = lab_sub_dir3+\"\\\\\" + path_4_lab\n",
    "                    if not os.path.exists(str(img_sub_dir4)):\n",
    "                        print(f\"sorry, I couldn't find file:{img_sub_dir4}\")\n",
    "                        continue\n",
    "                    if not os.path.exists(str(lab_sub_dir4)):\n",
    "                        print(f\"sorry, I couldn't find file:{lab_sub_dir4}\")\n",
    "                        continue\n",
    "                    list_img.append(img_sub_dir4)\n",
    "                    list_lab.append(lab_sub_dir4) \n",
    "    assert len(list_img)==len(list_lab)\n",
    "    print(f\"The length of  image dataset is {len(list_img)} and the length of label is{len(list_lab)}\")\n",
    "    totla_length = len(list_img)\n",
    "    sixth_part = int(totla_length * 0.6)\n",
    "    eigth_parth = int(totla_length * 0.8)\n",
    "    \n",
    "    all = pd.DataFrame({'image':list_img, 'label':list_lab})\n",
    "    all_shuffle = shuffle(all)\n",
    "    #ptint(all_shuffle)\n",
    "    \n",
    "    train_dataset = all_shuffle[:sixth_part]\n",
    "    val_dataset = all_shuffle[sixth_part:eigth_parth]\n",
    "    test_dataset = all_shuffle[eigth_parth:totla_length]\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linux系统读取文件 \n",
    "此处附上Linux系统下的文件读取，运用 **os.path.join()** 函数进行路径连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linux_img_path(path):\n",
    "    list_img = []\n",
    "    list_lab = []\n",
    "    for path_1 in os.listdir(path): \n",
    "        image_sub_dir1 = pjoin(path, path_1) #利用os.path.join()进行连接\n",
    "        label_sub_dir1 = pjoin(label_dir, 'Label_' + str.lower(path_1), 'Label')\n",
    "        for path_2 in os.listdir(image_sub_dir1):\n",
    "            image_sub_dir2 = pjoinn(image_sub_dir1, path_2)\n",
    "            label_sub_dir2 = pjoin(label_sub_dir1, path_2)\n",
    "            for path_3 in os.listdir(image_sub_dir2):\n",
    "                image_sub_dir3 = pjoin(image_sub_dir2, path_3)\n",
    "                label_sub_dir3 = pjoin(label_sub_dir2, path_3)\n",
    "                for path_4 in os.listdir(image_sub_dir3):\n",
    "                    path_4_lab = path_4.replace('.jpg','_bin.png')\n",
    "                    image_sub_dir4 = pjoin(image_sub_dir3, path_4)\n",
    "                    label_sub_dir4 = pjoin(label_sub_dir3, path_4_lab) \n",
    "                    if not os.path.exists(image_sub_dir4):\n",
    "                        print(image_sub_dir4)\n",
    "                        continue\n",
    "                    if not os.path.exists(label_sub_dir4):\n",
    "                        print(label_sub_dir4)\n",
    "                    list_img.append(image_sub_dir4)\n",
    "                    list_lab.append(label_sub_dir4)\n",
    "\n",
    "    assert len(list_img) == len(list_lab) \n",
    "    print(f\"The length of image dataset is {list_img}, and label is {list_lab}\")\n",
    "\n",
    "    total_length = len(list_img)\n",
    "\n",
    "    #划分dataset为 tarin：validate：test=6:2:2\n",
    "    sixth_part = int(total_length*0.6)\n",
    "    eighth_part = int(total_length*0.8)\n",
    "\n",
    "    all_data = pd.DataFrame({'image':list_img, 'label':list_lab})\n",
    "    all_shuffle = shuffle(all_data) #数据大乱，以防因认为因素而导致网络学习到错误的经验\n",
    "\n",
    "    train_dataset = all_shuffle[:sixth_part]#获取60%的数据为训练集\n",
    "    val_dataset = all_shuffle[sixth_part:eighth_part] #获取20%的数据为验证集\n",
    "    test_dataset = all_shuffle[eighth_part:] #获取20%的数据为测试集\n",
    "    return train_dataset, val_dataset, test_dataset  #返回三种数据结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of  image dataset is 21914 and the length of label is21914\n"
     ]
    }
   ],
   "source": [
    "data_dir = [img_dir, lab_dir]\n",
    "train_dataset, val_dataset, test_dataset = win_img_path(data_dir)\n",
    "\n",
    "#把读取的文件结果写入csv文件\n",
    "train_dataset.to_csv(\"F://BaiDuData//train.csv\")\n",
    "train_dataset.to_csv(\"F://BaiDuData//valid.csv\")\n",
    "train_dataset.to_csv(\"F://BaiDuData//test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
